{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oEJoZm2Bfeh",
        "outputId": "ca4ef256-9e0a-47dc-f699-b8cf5d60ceba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the dataset from http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar...\n",
            "Download complete!\n",
            "Extracting the dataset...\n",
            "Extraction complete!\n",
            "Creating a subset...\n",
            "Subset created.\n",
            "Compressed subset directory into images/subset/subset.zip\n",
            "You can find the compressed subset at: images/subset/subset.zip\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Function to download, extract, create a subset, and compress it\n",
        "def download_and_extract_dataset(dataset_url, tar_file_path, dataset_path, num_images_per_class=60):\n",
        "    if not os.path.exists(tar_file_path):\n",
        "        print(f\"Downloading the dataset from {dataset_url}...\")\n",
        "        urllib.request.urlretrieve(dataset_url, tar_file_path)\n",
        "        print(\"Download complete!\")\n",
        "\n",
        "    print(\"Extracting the dataset...\")\n",
        "    with tarfile.open(tar_file_path, 'r') as tar_ref:\n",
        "        tar_ref.extractall(path=dataset_path)\n",
        "    print(\"Extraction complete!\")\n",
        "\n",
        "    print(\"Creating a subset...\")\n",
        "    subset_path = os.path.join(dataset_path, 'subset')\n",
        "    os.makedirs(subset_path, exist_ok=True)\n",
        "\n",
        "    # Adjusting for the correct path within the extracted directory structure\n",
        "    dataset_path = os.path.join(dataset_path, 'Images')\n",
        "\n",
        "    breed_dirs = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
        "\n",
        "    for breed_dir in breed_dirs:\n",
        "        breed_path = os.path.join(dataset_path, breed_dir)\n",
        "        images = [img for img in os.listdir(breed_path) if os.path.isfile(os.path.join(breed_path, img))]\n",
        "        selected_images = random.sample(images, min(len(images), num_images_per_class))\n",
        "\n",
        "        target_breed_dir = os.path.join(subset_path, breed_dir)\n",
        "        os.makedirs(target_breed_dir, exist_ok=True)\n",
        "\n",
        "        for image in selected_images:\n",
        "            src = os.path.join(breed_path, image)\n",
        "            dst = os.path.join(target_breed_dir, image)\n",
        "            shutil.copy(src, dst)\n",
        "    print(\"Subset created.\")\n",
        "\n",
        "    # Compress the subset directory\n",
        "    compressed_subset_name = os.path.join(subset_path, 'subset.zip')\n",
        "    shutil.make_archive(subset_path, 'zip', subset_path)\n",
        "    print(f\"Compressed subset directory into {compressed_subset_name}\")\n",
        "\n",
        "    # Users should manually download the subset or you can automate this if needed\n",
        "    print(f\"You can find the compressed subset at: {compressed_subset_name}\")\n",
        "\n",
        "# Specify dataset URL, path to save the .tar file, and the path for dataset extraction\n",
        "dataset_url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\"\n",
        "tar_file_path = \"images.tar\"\n",
        "dataset_path = \"images\"\n",
        "\n",
        "# Download, extract, create a subset, and compress it\n",
        "download_and_extract_dataset(dataset_url, tar_file_path, dataset_path)"
      ]
    }
  ]
}