# Adversarial-Attacks-on-Deep-Learning-Model
The primary objective of this project, "Adversarial Attacks on DogBreedClassifier," is to investigate and demonstrate the profound impact of adversarial attacks, specifically the Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD), on a pre-trained machine learning model. 
